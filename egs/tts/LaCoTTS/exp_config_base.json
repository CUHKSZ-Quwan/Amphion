{
    "base_config": "config/tts.json",
    "model_type": "GPTTTS",
    "dataset": ["libritts360"],
    "preprocess": {
        "hop_size": 200,
        "sample_rate": 16000,
        "processed_dir": "",
        "train_file": "/data/zhanhaoyue/data/training_dataset/libritts360_en_toneipa/filelist_s2_fix_addspk_0319.json",
        "valid_file": "/data/zhanhaoyue/data/training_dataset/libritts360_en_toneipa/filelist_s2_fix_addspk_0319_valid.json"
    },
    "model": {
        "latent_codec": {
            "encoder": {
                "d_mel": 128,
                "d_model": 96,
                "num_blocks": 4,
                "out_channels": 256,
                "use_tanh": false,
                "pretrained_ckpt": "ckpts/latent_codec/latent_codec_enc.bin"
            },
            "decoder": {
                "in_channels": 256,
                "num_quantizers": 1,
                "codebook_size": 8192,
                "codebook_dim": 8,
                "quantizer_type": "fvq",
                "use_l2_normlize": true,
                "vocos_dim": 512,
                "vocos_intermediate_dim": 4096,
                "vocos_num_layers": 16,
                "ln_before_vq": true,
                "use_pe": false,
                "pretrained_ckpt": "ckpts/latent_codec/latent_codec_dec.bin" 
            },
            "pretrained_ckpt": "..."       
        },
        "wav_codec": {
            "encoder": {
                "d_model": 96,
                "out_channels": 128,
                "up_ratios": [2, 4, 5, 5],
                "use_tanh": false,
                "pretrained_ckpt": "ckpts/wav_codec/wav_codec_enc.bin" 
            },
            "decoder": {
                "in_channels": 128,
                "upsample_initial_channel": 1536,
                "num_quantizers": 8,
                "codebook_size": 1024,
                "codebook_dim": 128,
                "quantizer_type": "fvq",
                "quantizer_dropout": 0.5,
                "use_l2_normlize": true,
                "use_vocos": true,
                "vocos_dim": 512,
                "vocos_intermediate_dim": 4096,
                "vocos_num_layers": 24
            },
            "pretrained_ckpt": "..."
        },
        "gpt_tts": {
            "phone_vocab_size": 256,
            "target_vocab_size": 8192,
            "hidden_size": 1024,
            "intermediate_siz": 4096,
            "num_hidden_layer": 12,
            "num_attention_head": 16,
            "pad_token_id": 8448,
            "bos_target_id": 8449,
            "eos_target_id": 8450,
            "bos_phone_id": 8451,
            "eos_phone_id": 8452,
            "max_position_embeddings": 2048
        }
    },
    "log_dir": "libritts360",
    "train": {
        "max_epoch": 0,
        "use_dynamic_batchsize": true,
        "max_tokens": 192000,   // 1600000 = 16000 * 100 which means we use at most 100s speech for a batch
        "max_sentences": 8,
        "lr_warmup_steps": 32000,
        "lr_scheduler": "",
        "num_train_steps": 800000,
        "adam": {
            "lr": 1e-4
        },
        "ddp": false,
        "random_seed": 114,
        "batch_size": 8,
        "epochs": 5000,
        "max_steps": 1000000,
        "total_training_steps": 800000,
        "save_summary_steps": 500,
        "save_checkpoints_steps": 10000,
        "valid_interval": 2000,
        "keep_checkpoint_max": 50,
        "gradient_accumulation_step": 10,
        "tracker": ["tensorboard"],
        "save_checkpoint_stride": [1],
        "keep_last": [1000],
        "run_eval": [true],
        "dataloader": {
          "num_worker": 16,
          "pin_memory": true
        }
    }
}
