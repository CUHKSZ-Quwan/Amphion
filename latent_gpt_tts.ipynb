{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tts.gpt_tts.gpt_tts import GPTTTS\n",
    "from models.tts.gpt_tts.g2p_old_en import process, PHPONE2ID\n",
    "from g2p_en import G2p\n",
    "from models.codec.codec_latent.codec_latent import LatentCodecEncoder, LatentCodecDecoderWithTimbre\n",
    "from models.codec.amphion_codec.codec import CodecEncoder, CodecDecoder\n",
    "from utils.util import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config(\"egs/tts/LaCoTTS/exp_config_base.json\")\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Tokenizer: Convert Speech to Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_codec_enc = CodecEncoder(\n",
    "    cfg=cfg.model.wav_codec.encoder\n",
    ")\n",
    "wav_codec_dec = CodecDecoder(\n",
    "    cfg=cfg.model.wav_codec.decoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_codec_enc = LatentCodecEncoder(\n",
    "    cfg=cfg.model.latent_codec.encoder\n",
    ")\n",
    "latent_codec_dec = LatentCodecDecoderWithTimbre(\n",
    "    cfg=cfg.model.latent_codec.decoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_codec_enc.load_state_dict(torch.load(\"ckpts/wav_codec/wav_codec_enc.bin\"))\n",
    "wav_codec_dec.load_state_dict(torch.load(\"ckpts/wav_codec/wav_codec_dec.bin\"))\n",
    "latent_codec_enc.load_state_dict(torch.load(\"ckpts/latent_codec/latent_codec_enc.bin\"))\n",
    "latent_codec_dec.load_state_dict(torch.load(\"ckpts/latent_codec/latent_codec_dec.bin\"))\n",
    "\n",
    "wav_codec_enc.eval()\n",
    "wav_codec_dec.eval()\n",
    "latent_codec_enc.eval()\n",
    "latent_codec_dec.eval()\n",
    "\n",
    "wav_codec_enc.cuda()\n",
    "wav_codec_dec.cuda()\n",
    "latent_codec_enc.cuda()\n",
    "latent_codec_dec.cuda()\n",
    "\n",
    "# requires_grad false\n",
    "wav_codec_enc.requires_grad_(False)\n",
    "wav_codec_dec.requires_grad_(False)\n",
    "latent_codec_enc.requires_grad_(False)\n",
    "latent_codec_dec.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Codec Language Model TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_tts = GPTTTS(cfg=cfg.model.gpt_tts)\n",
    "gpt_tts.load_state_dict(torch.load(\"ckpts/gpt_tts/latent_codec_gpt_tts.bin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_tts.eval()\n",
    "gpt_tts.cuda()\n",
    "gpt_tts.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_text = \"and keeping erernity before the eyes\"\n",
    "target_text = \"Come, come returned Hawkeye, uncasing his honest countenance, the better to assure the wavering confidence of his companion. You may see a skin which, if it be not as white as one of the gentle ones, has no tinge of red to it that the winds of the heaven and the sun have not bestowed. Now, let us to business.\"\n",
    "source_wav = librosa.load(\"examples/ref/1.wav\", sr=16000)[0]\n",
    "Audio(source_wav, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text tokenize\n",
    "text = source_text + \" \" + target_text\n",
    "g2p = G2p()\n",
    "txt_struct, txt = process(text, g2p)\n",
    "phone_seq = [p for w in txt_struct for p in w[1]]\n",
    "phone_id = [PHPONE2ID[p] for p in phone_seq]\n",
    "phone_id = torch.LongTensor(phone_id).unsqueeze(0).cuda()\n",
    "phone_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speech tokenize\n",
    "prompt_wav = torch.FloatTensor(source_wav).cuda().unsqueeze(0)\n",
    "# wav to latent\n",
    "vq_emb = wav_codec_enc(prompt_wav.unsqueeze(1))\n",
    "vq_emb = latent_codec_enc(vq_emb)\n",
    "# latent to token\n",
    "(\n",
    "    _,\n",
    "    vq_indices,\n",
    "    _,\n",
    "    _,\n",
    "    _,\n",
    "    speaker_embedding,\n",
    ") = latent_codec_dec(vq_emb, vq=True, eval_vq=False, return_spk_embs=True)\n",
    "prompt_id = vq_indices[0,:,:]\n",
    "prompt_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_tokens = gpt_tts.sample_hf(\n",
    "    phone_id,\n",
    "    prompt_id,\n",
    "    max_length=3600,\n",
    "    temperature=0.9,\n",
    "    top_k=8192,\n",
    "    top_p=0.85,\n",
    "    repeat_penalty=1.0,\n",
    "    classifer_free_guidance=1.25,   # i find speech speed will be faster if we set cfg > 1.0; if you don't want it, set cfg = 1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen token to latent\n",
    "vq_post_emb = latent_codec_dec.vq2emb(gen_tokens.unsqueeze(0))\n",
    "recovered_latent = latent_codec_dec(\n",
    "    vq_post_emb, vq=False, speaker_embedding=speaker_embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconvered latent to wav\n",
    "recovered_audio = wav_codec_dec(recovered_latent, vq=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write(\"examples/recon/1.wav\", recovered_audio.squeeze().cpu().numpy(), 16000)\n",
    "Audio(\"examples/recon/1.wav\", rate=16000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
